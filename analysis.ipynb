{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "flu_rate = pd.read_csv('./data/170102_210531_influenza.csv')\n",
    "word_trends = pd.read_csv('./data/독감+증상_word_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_corr(x, y, max_lag=0):\n",
    "    '''\n",
    "    Args:\n",
    "        x (pandas.Series): fixed data\n",
    "        y (pandas.Series): data to be shifted\n",
    "    \n",
    "    Returns:\n",
    "        corr (pandas.Series): {0: XX.XX, 1: XX.XX, ..., max_lag: XX.XX}\n",
    "    '''\n",
    "    corr = {}\n",
    "    for lag in range(max_lag+1):\n",
    "        corr[lag] = x.corr(y.shift(lag))\n",
    "    return pd.Series(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 194.77it/s]\n"
     ]
    }
   ],
   "source": [
    "word_trends_with_lag = {word: cross_corr(flu_rate['ratio'], word_trends[word], max_lag=12)\n",
    "                         for word in tqdm(word_trends.columns[1:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_topn = []\n",
    "for word, corr in word_trends_with_lag.items():\n",
    "    lag = corr.argmax()\n",
    "    max_corr = corr[lag]\n",
    "    corr_topn.append((word, max_corr, lag))\n",
    "\n",
    "corr_topn.sort(key=(lambda x: x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Extract \"flu-related\" words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "kv_fname = 'kowiki-neg-300.kv'\n",
    "w2v_kv = KeyedVectors.load(f'./models/{kv_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('질병', 0.6456781029701233),\n",
       " ('합병증', 0.6416015028953552),\n",
       " ('패혈증', 0.6396576166152954),\n",
       " ('피부병', 0.6389033198356628),\n",
       " ('황달', 0.637260377407074),\n",
       " ('매독', 0.6342878341674805),\n",
       " ('기관지염', 0.6325851678848267),\n",
       " ('폐렴', 0.6323192715644836),\n",
       " ('급성', 0.6281660795211792),\n",
       " ('복통', 0.6278930902481079)]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "w2v_kv.most_similar_cosmul(positive=['독감', '증상'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "flu_related_words = ['독감'] + [w for w, _ in w2v_kv.most_similar_cosmul(positive=['독감', '증상'], topn=1000)]\n",
    "pyt = TrendReq(hl='ko-KR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "199it [21:14,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, keywords in tqdm(enumerate(chunks(flu_related_words, 5))):\n",
    "    try:\n",
    "        pyt.build_payload(keywords, timeframe='2017-01-01 2021-06-05', geo='KR')\n",
    "        trends = pd.concat([trends, pyt.interest_over_time()], axis=1)\n",
    "        trends.pop('isPartial')\n",
    "        trends.to_csv('./data/독감+증상_google_trends.csv')\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        print(i, keywords)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            독감  질병  합병증  패혈증  피부병  황달  매독  기관지염  폐렴  급성  ...  성욕  뇌막  뇌일혈  \\\n",
       "date                                                     ...                \n",
       "2017-01-01  16   6    1    0    2   0   0     0   1   0  ...  68   0    0   \n",
       "2017-01-08  10   6    1    1    1   0   0     0   1   0  ...  55   0    0   \n",
       "2017-01-15   9   5    1    0    1   1   0     0   1   1  ...  42   0    0   \n",
       "2017-01-22   3   4    1    1    2   0   0     0   1   1  ...  40   0    0   \n",
       "2017-01-29   2   5    2    1    1   0   0     0   1   2  ...  65   0    0   \n",
       "...         ..  ..  ...  ...  ...  ..  ..   ...  ..  ..  ...  ..  ..  ...   \n",
       "2021-05-02   3  22    1    2    1   0   0     0   1   1  ...  33   0    0   \n",
       "2021-05-09   3  33    2    1    0   0   0     0   1   1  ...  39   0    0   \n",
       "2021-05-16   3  17    2    1    0   0   0     0   1   1  ...  40   0    0   \n",
       "2021-05-23   2  26    0    2    0   0   0     0   1   1  ...  44   0    0   \n",
       "2021-05-30   3  36    1    0    3   0   0     0   1   1  ...  52   0    0   \n",
       "\n",
       "            에리트로포이에틴  원추각막  열대병  요법  마비저  손상  통풍  \n",
       "date                                              \n",
       "2017-01-01         0     0    0  63    0  63  52  \n",
       "2017-01-08         0     4    0  52    0  37  61  \n",
       "2017-01-15         0     0    0  40    0  44  41  \n",
       "2017-01-22         0     0    0  31    0  35  29  \n",
       "2017-01-29         0     0    0  46    0  21  18  \n",
       "...              ...   ...  ...  ..  ...  ..  ..  \n",
       "2021-05-02         0     4    0  31    0  47  37  \n",
       "2021-05-09         0     0    0  40    0  34  35  \n",
       "2021-05-16         0     0    0  37    0  61  35  \n",
       "2021-05-23         0     0    0  32    0  47  63  \n",
       "2021-05-30         0     0    0  35    0  63  55  \n",
       "\n",
       "[231 rows x 1001 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>독감</th>\n      <th>질병</th>\n      <th>합병증</th>\n      <th>패혈증</th>\n      <th>피부병</th>\n      <th>황달</th>\n      <th>매독</th>\n      <th>기관지염</th>\n      <th>폐렴</th>\n      <th>급성</th>\n      <th>...</th>\n      <th>성욕</th>\n      <th>뇌막</th>\n      <th>뇌일혈</th>\n      <th>에리트로포이에틴</th>\n      <th>원추각막</th>\n      <th>열대병</th>\n      <th>요법</th>\n      <th>마비저</th>\n      <th>손상</th>\n      <th>통풍</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-01</th>\n      <td>16</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63</td>\n      <td>0</td>\n      <td>63</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>2017-01-08</th>\n      <td>10</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>52</td>\n      <td>0</td>\n      <td>37</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>2017-01-15</th>\n      <td>9</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>44</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>2017-01-22</th>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n      <td>0</td>\n      <td>35</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>2017-01-29</th>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46</td>\n      <td>0</td>\n      <td>21</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-05-02</th>\n      <td>3</td>\n      <td>22</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>31</td>\n      <td>0</td>\n      <td>47</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2021-05-09</th>\n      <td>3</td>\n      <td>33</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>34</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2021-05-16</th>\n      <td>3</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n      <td>0</td>\n      <td>61</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2021-05-23</th>\n      <td>2</td>\n      <td>26</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>47</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>2021-05-30</th>\n      <td>3</td>\n      <td>36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35</td>\n      <td>0</td>\n      <td>63</td>\n      <td>55</td>\n    </tr>\n  </tbody>\n</table>\n<p>231 rows × 1001 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "trends"
   ]
  },
  {
   "source": [
    "## Make wor2vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Making sentences as list...\n",
      "Making word vectors...\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "min_count = 5\n",
    "window_size = 5\n",
    "num_neg = 15\n",
    "vector_size = 300\n",
    "\n",
    "print('Making sentences as list...')\n",
    "sents = []\n",
    "corpus_fname = 'kowiki_corpus.txt'\n",
    "\n",
    "with open(f'./data/{corpus_fname}', 'r', encoding='utf8') as fin:\n",
    "    line = fin.readline()\n",
    "    while line:\n",
    "        words = line.split()\n",
    "        sents.append(words)\n",
    "        line = fin.readline()\n",
    "\n",
    "print('Making word vectors...')\n",
    "w2v_model = Word2Vec(sents, vector_size=vector_size, min_count=min_count, negative=num_neg, window=window_size)\n",
    "\n",
    "w2v_model.save('./models/kowiki-neg-300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('인플루엔자', 0.7366062998771667),\n",
       " ('홍역', 0.6661979556083679),\n",
       " ('콜레라', 0.652269721031189),\n",
       " ('출혈열', 0.648910641670227),\n",
       " ('유행병', 0.6479013562202454),\n",
       " ('전염병', 0.6393334269523621),\n",
       " ('뎅기열', 0.6355220079421997),\n",
       " ('대유행', 0.6307356357574463),\n",
       " ('말라리아', 0.6306702494621277),\n",
       " ('광견병', 0.6233310103416443)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('독감')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_kv = w2v_model.wv\n",
    "w2v_kv.save('./models/kowiki-neg-300.kv')"
   ]
  },
  {
   "source": [
    "## Build corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "wiki_fname = 'kowiki-latest-pages-articles.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):    \n",
    "    # Common\n",
    "    text = re.sub(\"(?s)<ref>.+?</ref>\", \"\", text) # remove reference links\n",
    "    text = re.sub(\"(?s)<[^>]+>\", \"\", text) # remove html tags\n",
    "    text = re.sub(\"&[a-z]+;\", \"\", text) # remove html entities\n",
    "    text = re.sub(\"(?s){{.+?}}\", \"\", text) # remove markup tags\n",
    "    text = re.sub(\"(?s){.+?}\", \"\", text) # remove markup tags\n",
    "    text = re.sub(\"(?s)\\[\\[([^]]+\\|)\", \"\", text) # remove link target strings\n",
    "    text = re.sub(\"(?s)\\[\\[([^]]+\\:.+?]])\", \"\", text) # remove media links\n",
    "    \n",
    "    text = re.sub(\"[']{5}\", \"\", text) # remove italic+bold symbols\n",
    "    text = re.sub(\"[']{3}\", \"\", text) # remove bold symbols\n",
    "    text = re.sub(\"[']{2}\", \"\", text) # remove italic symbols\n",
    "    \n",
    "    text = re.sub(u\"[^\\s\\r\\n가-힣.?!]\", \" \", text) # Replace unacceptable characters with a space.\n",
    "    text = re.sub('([.?!]){2,}', '\\\\1', text) # remove repeated punctuation\n",
    "    text = re.sub('\\s[.?!]\\s', '', text) # remove isolated punctuation\n",
    "    \n",
    "    # Common\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text) # Squeeze spaces.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_segment(text):\n",
    "    '''\n",
    "    Args:\n",
    "      text: A string. A unsegmented paragraph.\n",
    "    \n",
    "    Returns:\n",
    "      A list of sentences.\n",
    "    '''\n",
    "    return re.split('([.?!])?[\\n]+|[.?!] ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "def word_segment(text):\n",
    "    return [word for word, _ in mecab.pos(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{wiki_fname.split(\"-\")[0]}_corpus.txt', 'w', encoding='utf-8') as fout:\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "25979812it [30:56, 13991.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "ns = '{http://www.mediawiki.org/xml/export-0.10/}'\n",
    "with open(f'./data/{wiki_fname.split(\"-\")[0]}_corpus.txt', 'w', encoding='utf-8') as fout:\n",
    "    for _, elem in tqdm(ET.iterparse(f'./data/{wiki_fname}')):\n",
    "        try:\n",
    "            tag = elem.tag.replace(ns, '')\n",
    "            if tag == 'text':\n",
    "                running_text = clean_text(elem.text)\n",
    "                sents = sentence_segment(running_text)\n",
    "                for sent in sents:\n",
    "                    if sent:\n",
    "                        words = word_segment(sent)\n",
    "                        if len(words) > 10:\n",
    "                            fout.write(' '.join(words) + '\\n')\n",
    "        except:\n",
    "            continue\n",
    "        elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}